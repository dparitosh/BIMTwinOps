# Ollama Configuration for SMART_BIM
# Set these environment variables to use Ollama instead of Azure OpenAI

# LLM Provider Selection
LLM_PROVIDER=ollama

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:1b

# Your installed models:
# OLLAMA_MODEL=llama3.2:1b      # Small, fast (1.23 GB)
# OLLAMA_MODEL=llama3:latest    # Larger, more capable (4.34 GB)
# OLLAMA_MODEL=gemma3:4b        # Google's model (3.11 GB)
# OLLAMA_MODEL=nomic-embed-text # For embeddings only

# To install Ollama:
# 1. Download from https://ollama.ai
# 2. Run: ollama pull llama3.2
# 3. Verify: curl http://localhost:11434/api/tags

# Note: This project uses a dedicated Ollama HTTP client (no optional LangChain provider packages required).
